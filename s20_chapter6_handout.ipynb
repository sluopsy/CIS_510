{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Chapter 6</h1>\n",
        "</center>\n",
        "\n",
        "In this chapter we will make some final tune-ups to the Naive Bayes algorithm. Then you can do the fun part: check how well it does with the Gothic authors (spoiler alert: not bad).\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zcab0aNw7_f3"
      },
      "source": [
        "#1. First let's bring in puddles\n",
        "\n",
        "\n",
        "<img src='https://www.dropbox.com/s/zv84ew76m7ptyrh/puddles.jpeg?raw=1' height=100>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_GdU8ACeitW"
      },
      "source": [
        "#flush the old directory\n",
        "!rm -r  'uo_puddles'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPISZH5nclhU"
      },
      "source": [
        "my_github_name = 'uo-puddles'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuaxZXKXcrNL"
      },
      "source": [
        "clone_url = f'https://github.com/{my_github_name}/uo_puddles.git'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmp86ySdkr4z",
        "outputId": "8908c50b-3f44-4259-d850-7241b7c0f78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#this adds the library to colab so you can now import it\n",
        "!git clone $clone_url  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'uo_puddles'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 228 (delta 135), reused 64 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (228/228), 57.48 KiB | 346.00 KiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8-rTeMkr5C"
      },
      "source": [
        "import uo_puddles.uo_puddles as up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dagqgRpTyPl"
      },
      "source": [
        "#2. Now bring in spacy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vilI8ZGqZPDB"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-yQfqTyeMU",
        "outputId": "eee5c29b-3154-4657-81d2-db1c8ccdbed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "#you first have to get colab to download it locally\n",
        "\n",
        "!python -m spacy download en_core_web_md\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD4w_Bdo-gZ1"
      },
      "source": [
        "#now you can import the dictionary and set up a parser\n",
        "\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()  #huh?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAuPW0XhZ5UJ"
      },
      "source": [
        "#3. Bring in data set\n",
        "\n",
        "\n",
        "&nbsp;<br>&nbsp;<br>\n",
        "<center>\n",
        "<img src='https://www.thegreatcoursesdaily.com/wp-content/uploads/2017/03/Mary-Shelly-Featured-Image-LARGE.jpg' height='150' >\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src ='https://www.riverwoodwinery.com/uploads/1/2/4/1/124189002/s593933943352694433_p9_i1_w593.jpeg' height='150'>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src='https://wpcdn.us-midwest-1.vip.tn-cloud.net/www.rimonthly.com/content/uploads/2017/05/13135413/4b8e1f244f4e0e42bf881efabd19aa12-AU5EC102CUR.jpg' height='150'>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74AsQuj4bvej"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K713HblbzsA",
        "outputId": "573f274d-ffd7-4de7-d5b2-d3419da1be59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gothic_sentences = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQqRwyE0ceZREKqhuaOw8uQguTG6Alr5kocggvAnczrWaimXE8ncR--GC0o_PyVDlb-R6Z60v-XaWm9/pub?output=csv',\n",
        "                          encoding='utf-8')\n",
        "len(gothic_sentences) #how many sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Mf50alDxa6"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)  #None forces all of sentence to be shown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpZqCAKyD_Uu",
        "outputId": "515a48af-613f-4cde-e928-0b4ce3acbdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "gothic_sentences.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... author\n",
              "0  id26305  ...    EAP\n",
              "1  id17569  ...    HPL\n",
              "2  id11008  ...    EAP\n",
              "3  id27763  ...    MWS\n",
              "4  id12958  ...    HPL\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aedN9YTZdaFl"
      },
      "source": [
        "#4. Compute holdout data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g3Q9PBZZ_G5"
      },
      "source": [
        "our_seed = 1234  #if we all use this we should get same random data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoT_UF0hhdmA"
      },
      "source": [
        "import numpy as np  #powerful library for manipulating data\n",
        "rsgen = np.random.RandomState(our_seed)  #we are only going to use numpy's random number generator for now"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vStMqeJhiPEh"
      },
      "source": [
        "shuffled_table = gothic_sentences.sample(frac=1, random_state=rsgen).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vcUvTIfnoyd",
        "outputId": "949828d8-ca54-4344-a134-b9ff602b9c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(shuffled_table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRLat0NJmR7S",
        "outputId": "1a4ae470-8cfe-4970-9328-ccd604e07bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "19579*.7  #split point"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13705.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxslltTfmbks"
      },
      "source": [
        "training_table = shuffled_table[:13705].reset_index(drop=True)  #.7\n",
        "testing_table = shuffled_table[13705:].reset_index(drop=True)   #.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXfPhQ4hQFPM"
      },
      "source": [
        "Now pull the sentences into list of strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSCKZHlqnITo"
      },
      "source": [
        "training_text = training_table['text'].to_list()\n",
        "training_authors = training_table['author'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBpfNZXS-1E0"
      },
      "source": [
        "testing_text = testing_table['text'].to_list()\n",
        "testing_authors = testing_table['author'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hadtnfkS96nm"
      },
      "source": [
        "#5. Bring in word bag\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyAbmgU6P4S1"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW0vmVc02Vfw"
      },
      "source": [
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQR107nAfeU_z-p6sUv3yhnti9vNsklgXsm2RXAExQBHPUE3APm32qMQxTuYCEBbSz09MCVx-rnOXGb/pub?output=csv'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTy80-RHv8sN"
      },
      "source": [
        "sorted_word_table = pd.read_csv(url, dtype={'word':str}, encoding='utf-8',\n",
        "                                index_col='word', na_filter=False)\n",
        "sorted_word_table = sorted_word_table.rename(index={'TRUE': 'true', 'FALSE': 'false'}) #need this because of bug in reading from url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6j6fjlk2zsP",
        "outputId": "ad54a829-ed31-4da6-bd3f-75f202607662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "sorted_word_table.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EAP</th>\n",
              "      <th>MWS</th>\n",
              "      <th>HPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ab</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aback</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaft</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abandon</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abandoned</th>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           EAP  MWS  HPL\n",
              "word                    \n",
              "ab           1    0    0\n",
              "aback        2    0    0\n",
              "abaft        0    1    0\n",
              "abandon      3    1    2\n",
              "abandoned    8    4    8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymK0iXhulH4R"
      },
      "source": [
        "#6. Now, about those zero values\n",
        "\n",
        "The Naive Bayes algorithm is rather strict on zeroes. Reminder of the formula:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/gstzvvtvh9b39o8/bayes.png?raw=1'>\n",
        "\n",
        "Because we are taking the product and not the sum in the denominator, any P(Ei|O) that is zero will cause the entire probability to be zero. This makes sense in some ideal setting where we know everything. In particular, we know all the works by each author and we know what words they used absolutely. So if we get a P(indefinite|EAP) as zero, then we absoultely can remove EAP from consideration.\n",
        "\n",
        "Kind of bold of us to say we know everything. Laplace took this question up as well under a different guise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk60AdaOeTeb"
      },
      "source": [
        "#Laplace was smooth\n",
        "\n",
        "<img src='https://www.dropbox.com/s/1qjraurrneanzjo/Screenshot%202019-09-27%2013.47.01.png?raw=1'>\n",
        "\n",
        "From his bio: <i>Laplace is remembered as one of the greatest scientists of all time. Sometimes referred to as the French Newton or Newton of France, he has been described as possessing a phenomenal natural mathematical faculty superior to that of any of his contemporaries. He was Napoleon's examiner when Napoleon attended the Ã‰cole Militaire in Paris in 1784. Laplace became a count of the Empire in 1806 and was named a marquis in 1817, after the Bourbon Restoration.\n",
        "Laplace died in Paris in 1827. His brain was removed by his physician, FranÃ§ois Magendie, and kept for many years, eventually being displayed in a roving anatomical museum in Britain. It was reportedly smaller than the average brain.</i>\n",
        "\n",
        "Cool, but what does that have to do with us? Well, Laplace was also into thought experiments. He was thinking about the probability that the sun would **not** rise in the morning.\n",
        "His thought was that given a large sample of days with the rising sun, we still can not be completely sure that it will rise tomorrow. So the probability of it not rising is not zero, even though we have no evidence of it to date. He proposed adding a small smoothing constant to each conditional probability. In essence, he did not like probablities of 0. He thought a 0 led to us thinking we knew more than we actually did.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J0slaJrtezw"
      },
      "source": [
        "#9. The Laplace smoothing factor\n",
        "\n",
        "I hope you see that Laplace was correct when it comes to our hold-out method. We can easily see a word in the testing set that does not appear in the training set. And if it does not appear in the training set, then it is not in our word bag. My default would be to give a zero to such a word. But that means we will end up with a probability of zero for all 3 authors. Not good!\n",
        "\n",
        "I can boil down the Laplace smoothing factor, to mitigate this unseen word problem, as follows:\n",
        "\n",
        "1. For `P(oliver|EAP)` we normally have (a) how many times EAP used `oliver` divided by (b) how many sentences EAP wrote. I am going to modify the numerator by adding 1. So if the numerator is 0, which it is in this case, it becomes 1. If it was 1, it becomes 2. Just add 1 in all cases. In essence, this is like **adding 1 to all the words in the EAP column**.\n",
        "\n",
        "2. If a word is unseen (does not appear in word bag), then I treat it as 0 count. But then I add 1 to it.\n",
        "\n",
        "3. Now we have the problem that we have \"shifted\" the EAP column by 1*|V|, where V is the vocabulary and |V| is the number of words we have in V, i.e., the length of the sorted_word_table. To compensate, I am going to divide by |V|. \n",
        "\n",
        "We should now never get a value of zero for any `P(word|author)` that we need to calculate. \n",
        "\n",
        "Whew.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiSjiQczjIIq"
      },
      "source": [
        "##Side note\n",
        "\n",
        "The smoothing value of 1 may not be the best. Some have argued (see link below) that it gives too much weight to outliers. They argue for something closer to .001. So add .01 to numerator and .01*|V| to denominator.\n",
        "\n",
        "http://www.cs.virginia.edu/~kc2wc/teaching/NLP16/slides/03-smooth.pdf\n",
        "\n",
        "In the end, it is yet another hyperparameter that you may need to explore. We will stick with 1 for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31gbI99re5ja"
      },
      "source": [
        "##Let's run through by hand again with new concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9ID_tXT6VeX"
      },
      "source": [
        "##Probabilites of authors P(O)\n",
        "\n",
        "These will not change - they are constant. So we only have to compute them once then can reuse them in the formula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW7N9lHi6cu1",
        "outputId": "62b5f539-a4ea-4281-ce61-c9bedb76a116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v_size = len(sorted_word_table)  #i.e., |V|\n",
        "v_size  #21552"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ7Ybld2nZr4",
        "outputId": "cb303672-a218-4e06-b7f1-53e686bff1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n = len(training_table)  #number of sentences total\n",
        "n  #13705"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDVl_p365fn",
        "outputId": "441e3ed1-2ff4-4a1e-d4c6-e98a3e0e7649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "eap_count = training_authors.count('EAP')\n",
        "eap_count  #5470"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayvrOH1i7BSY",
        "outputId": "1142c4c5-099f-4001-dc24-0dc1f9212a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mws_count = training_authors.count('MWS')\n",
        "mws_count  #4278"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Qz9w-O7Ban"
      },
      "source": [
        "hpl_count = training_authors.count('HPL')\n",
        "hpl_count  #3957"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0_Q7x_f7O71",
        "outputId": "7079ae8c-1a4d-4a67-b66d-133586a151f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p_eap = eap_count/n  #P(EAP)\n",
        "p_eap  #0.39912440715067493"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39912440715067493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZYzQKIr7bn0",
        "outputId": "f2ce7e17-0d10-4664-8efc-f2c570bec814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p_mws = mws_count/n  #P(MWS)\n",
        "p_mws  #0.31214885078438526"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31214885078438526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WR1Ec4q7bs8",
        "outputId": "29408519-1307-4dbb-e0bf-3bf60a5f1741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p_hpl = hpl_count/n  #P(HPL)\n",
        "p_hpl  #0.2887267420649398"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2887267420649398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZqj3zto51n0"
      },
      "source": [
        "##Compute P(indefinite|EAP)\n",
        "\n",
        "First, the old way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-tZwbnU82cA",
        "outputId": "726e0147-2d2f-486c-94e9-c0c9cbc798ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#count the number of sentences eap wrote. Out of those, how many used indefinite?\n",
        "p_indefinite_eap_old = sorted_word_table.loc['indefinite', 'EAP']/eap_count\n",
        "p_indefinite_eap_old  #0.0018281535648994515"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0018281535648994515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM8PRML7UZrr"
      },
      "source": [
        "Now with Laplace smoothing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWcRNvOr5Vkj"
      },
      "source": [
        "total_vocab = len(sorted_word_table)  #how many unique non-stop words we found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbobcg1SUYy1",
        "outputId": "6e2d10c6-c9c1-40c4-a203-54a15ff19337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "indefinite_count = 0  #start with assuming the word has not been seen before\n",
        "if 'indefinite' in sorted_word_table.index:\n",
        "  indefinite_count = sorted_word_table.loc['indefinite', 'EAP']  #if has been seen so get its value\n",
        "\n",
        "p_indefinite_eap = (indefinite_count + 1)/(eap_count + v_size)  #laplace smoothing\n",
        "p_indefinite_eap  #0.00040707571608319146"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00040707571608319146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYGEuhujWU9u"
      },
      "source": [
        "Let's try 'oliver'. EAP never used it according to the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FrT5252WaDn",
        "outputId": "1a1b0d0e-edd0-411f-ac2d-a990941eb4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "oliver_count = 0  #in case it is a word that has not been seen\n",
        "if 'oliver' in sorted_word_table.index:\n",
        "  oliver_count = sorted_word_table.loc['oliver', 'EAP']  #if has been seen get its value\n",
        "\n",
        "p_oliver_eap = (oliver_count + 1)/(eap_count + v_size)\n",
        "p_oliver_eap  #3.7006883280290134e-05"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7006883280290134e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h1aYR4fi7I5",
        "outputId": "01391c6b-50a2-4902-8db6-51bf5bbfabac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(0 + 1)/(eap_count + v_size) #just checking. We know oliver_count is 0."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7006883280290134e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vkYqVJlWy7O"
      },
      "source": [
        "Small, but not zero. Laplace would be happy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iCVzcOL96fn"
      },
      "source": [
        "#10. Ignore denominator\n",
        "\n",
        "How about P(indefinite)? I'm going to ignore it. What, you say, you are going to throw out all those P(word) terms? You can't just willy-nilly remove things. But I can :)\n",
        "\n",
        "First part of argument. Those P(Ei) terms are the same in each of the 3 instances we need to compute.\n",
        "<pre>\n",
        "P(EAP|E1, E2 ...) = ...\n",
        "P(MWS|E1, E2 ...) = ...\n",
        "P(HPL|E1, E2 ...) = ...\n",
        "</pre>\n",
        "So I can treat denominator as a constant. Now check this out.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AS0RBNOoDOP",
        "outputId": "1f146292-9dc0-470a-8e9c-11f0dbf5a4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p1 = .5\n",
        "p2 = .4\n",
        "\n",
        "p1 > p2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qooQpBoOsi",
        "outputId": "ed483b96-6830-47c2-f050-4189088568e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = .01  #our simulated denominator\n",
        "\n",
        "p1/c > p2/c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdHUqHDioBei"
      },
      "source": [
        "\n",
        "Second part of argument. I can use the mathematical notion of proportionality to remove them without changing the ordering of the 3 probabilities. For instance, if P(EAP|E1, E2 ...) > P(MWS|E1, E2 ...) when I include them, the same will hold when I remove them.\n",
        "\n",
        "That helps. Speeds things up and allows us to avoid dealing with P(Ei) = 0 which would give us a zero in the denominator. Cool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcVuOfF2lgpd"
      },
      "source": [
        "#11. Underflow or The vanishing gradient\n",
        "\n",
        "A new problem has arisen with Naives Bayes, one that was not an issue with the distance measures we used for KNN. The new problem is taking the product of very small numbers. In essence, calculating the numerator in Naive Bayes. Multiplying a set of very small numbers in Python can cause what is called *underflow*. What happens is that the product gets so small that Python turns the final result into zero. This is kind of bad. Defeats our whole process of adding a smoothing factor. Let me see if I can show you with an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puitr_1svQke",
        "outputId": "d68b7d1e-0fbc-461a-90af-63a495545d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "s = testing_text[5457]  #a sentence from our testing text\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To chambers of painted state farewell To midnight revelry, and the panting emulation of beauty, to costly dress and birth day shew, to title and the gilded coronet, farewell Farewell to the giant powers of man, to knowledge that could pilot the deep drawing bark through the opposing waters of shoreless ocean, to science that directed the silken balloon through the pathless air, to the power that could put a barrier to mighty waters, and set in motion wheels, and beams, and vast machinery, that could divide rocks of granite or marble, and make the mountains plain Farewell to the arts, to eloquence, which is to the human mind as the winds to the sea, stirring, and then allaying it; farewell to poetry and deep philosophy, for man\\'s imagination is cold, and his enquiring mind can no longer expatiate on the wonders of life, for \"there is no work, nor device, nor knowledge, nor wisdom in the grave, whither thou goest\" to the graceful building, which in its perfect proportion transcended the rude forms of nature, the fretted gothic and massy saracenic pile, to the stupendous arch and glorious dome, the fluted column with its capital, Corinthian, Ionic, or Doric, the peristyle and fair entablature, whose harmony of form is to the eye as musical concord to the ear farewell to sculpture, where the pure marble mocks human flesh, and in the plastic expression of the culled excellencies of the human shape, shines forth the god farewell to painting, the high wrought sentiment and deep knowledge of the artists\\'s mind in pictured canvas to paradisaical scenes, where trees are ever vernal, and the ambrosial air rests in perpetual glow: to the stamped form of tempest, and wildest uproar of universal nature encaged in the narrow frame, O farewell Farewell to music, and the sound of song; to the marriage of instruments, where the concord of soft and harsh unites in sweet harmony, and gives wings to the panting listeners, whereby to climb heaven, and learn the hidden pleasures of the eternals Farewell to the well trod stage; a truer tragedy is enacted on the world\\'s ample scene, that puts to shame mimic grief: to high bred comedy, and the low buffoon, farewell Man may laugh no more.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zJeNP8TveqW"
      },
      "source": [
        "doc = nlp(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSRZ4vselyzF",
        "outputId": "8591513c-efdd-41e1-a1a7-3f8e2c42de75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(doc)  #436 words before removing stop words. A long sentence!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_iUJ-d7vi39",
        "outputId": "34661369-376e-46ce-8a05-a8fdf3e2bfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s_list = []\n",
        "\n",
        "for i in range(len(doc)):\n",
        "  token = doc[i]\n",
        "  if token.is_alpha and not token.is_stop:\n",
        "    s_list.append(token.text)\n",
        "\n",
        "s_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chambers',\n",
              " 'painted',\n",
              " 'state',\n",
              " 'farewell',\n",
              " 'midnight',\n",
              " 'revelry',\n",
              " 'panting',\n",
              " 'emulation',\n",
              " 'beauty',\n",
              " 'costly',\n",
              " 'dress',\n",
              " 'birth',\n",
              " 'day',\n",
              " 'shew',\n",
              " 'title',\n",
              " 'gilded',\n",
              " 'coronet',\n",
              " 'farewell',\n",
              " 'Farewell',\n",
              " 'giant',\n",
              " 'powers',\n",
              " 'man',\n",
              " 'knowledge',\n",
              " 'pilot',\n",
              " 'deep',\n",
              " 'drawing',\n",
              " 'bark',\n",
              " 'opposing',\n",
              " 'waters',\n",
              " 'shoreless',\n",
              " 'ocean',\n",
              " 'science',\n",
              " 'directed',\n",
              " 'silken',\n",
              " 'balloon',\n",
              " 'pathless',\n",
              " 'air',\n",
              " 'power',\n",
              " 'barrier',\n",
              " 'mighty',\n",
              " 'waters',\n",
              " 'set',\n",
              " 'motion',\n",
              " 'wheels',\n",
              " 'beams',\n",
              " 'vast',\n",
              " 'machinery',\n",
              " 'divide',\n",
              " 'rocks',\n",
              " 'granite',\n",
              " 'marble',\n",
              " 'mountains',\n",
              " 'plain',\n",
              " 'Farewell',\n",
              " 'arts',\n",
              " 'eloquence',\n",
              " 'human',\n",
              " 'mind',\n",
              " 'winds',\n",
              " 'sea',\n",
              " 'stirring',\n",
              " 'allaying',\n",
              " 'farewell',\n",
              " 'poetry',\n",
              " 'deep',\n",
              " 'philosophy',\n",
              " 'man',\n",
              " 'imagination',\n",
              " 'cold',\n",
              " 'enquiring',\n",
              " 'mind',\n",
              " 'longer',\n",
              " 'expatiate',\n",
              " 'wonders',\n",
              " 'life',\n",
              " 'work',\n",
              " 'device',\n",
              " 'knowledge',\n",
              " 'wisdom',\n",
              " 'grave',\n",
              " 'thou',\n",
              " 'goest',\n",
              " 'graceful',\n",
              " 'building',\n",
              " 'perfect',\n",
              " 'proportion',\n",
              " 'transcended',\n",
              " 'rude',\n",
              " 'forms',\n",
              " 'nature',\n",
              " 'fretted',\n",
              " 'gothic',\n",
              " 'massy',\n",
              " 'saracenic',\n",
              " 'pile',\n",
              " 'stupendous',\n",
              " 'arch',\n",
              " 'glorious',\n",
              " 'dome',\n",
              " 'fluted',\n",
              " 'column',\n",
              " 'capital',\n",
              " 'Corinthian',\n",
              " 'Ionic',\n",
              " 'Doric',\n",
              " 'peristyle',\n",
              " 'fair',\n",
              " 'entablature',\n",
              " 'harmony',\n",
              " 'form',\n",
              " 'eye',\n",
              " 'musical',\n",
              " 'concord',\n",
              " 'ear',\n",
              " 'farewell',\n",
              " 'sculpture',\n",
              " 'pure',\n",
              " 'marble',\n",
              " 'mocks',\n",
              " 'human',\n",
              " 'flesh',\n",
              " 'plastic',\n",
              " 'expression',\n",
              " 'culled',\n",
              " 'excellencies',\n",
              " 'human',\n",
              " 'shape',\n",
              " 'shines',\n",
              " 'forth',\n",
              " 'god',\n",
              " 'farewell',\n",
              " 'painting',\n",
              " 'high',\n",
              " 'wrought',\n",
              " 'sentiment',\n",
              " 'deep',\n",
              " 'knowledge',\n",
              " 'artists',\n",
              " 'mind',\n",
              " 'pictured',\n",
              " 'canvas',\n",
              " 'paradisaical',\n",
              " 'scenes',\n",
              " 'trees',\n",
              " 'vernal',\n",
              " 'ambrosial',\n",
              " 'air',\n",
              " 'rests',\n",
              " 'perpetual',\n",
              " 'glow',\n",
              " 'stamped',\n",
              " 'form',\n",
              " 'tempest',\n",
              " 'wildest',\n",
              " 'uproar',\n",
              " 'universal',\n",
              " 'nature',\n",
              " 'encaged',\n",
              " 'narrow',\n",
              " 'frame',\n",
              " 'O',\n",
              " 'farewell',\n",
              " 'Farewell',\n",
              " 'music',\n",
              " 'sound',\n",
              " 'song',\n",
              " 'marriage',\n",
              " 'instruments',\n",
              " 'concord',\n",
              " 'soft',\n",
              " 'harsh',\n",
              " 'unites',\n",
              " 'sweet',\n",
              " 'harmony',\n",
              " 'gives',\n",
              " 'wings',\n",
              " 'panting',\n",
              " 'listeners',\n",
              " 'climb',\n",
              " 'heaven',\n",
              " 'learn',\n",
              " 'hidden',\n",
              " 'pleasures',\n",
              " 'eternals',\n",
              " 'Farewell',\n",
              " 'trod',\n",
              " 'stage',\n",
              " 'truer',\n",
              " 'tragedy',\n",
              " 'enacted',\n",
              " 'world',\n",
              " 'ample',\n",
              " 'scene',\n",
              " 'puts',\n",
              " 'shame',\n",
              " 'mimic',\n",
              " 'grief',\n",
              " 'high',\n",
              " 'bred',\n",
              " 'comedy',\n",
              " 'low',\n",
              " 'buffoon',\n",
              " 'farewell',\n",
              " 'Man',\n",
              " 'laugh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XA8lBNHxqfX",
        "outputId": "a3403c6b-ddb4-4885-f81d-896b86897382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(s_list)  #205 legit words. Still a lot."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Xa2HyrxujW"
      },
      "source": [
        "Yikes. 205 tokens in the sentence.\n",
        "\n",
        "Let's get the 205 values for P(Ei|EAP)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9UAaAoJwLWG",
        "outputId": "1b81ecb1-6335-45ea-e7d8-e105585204c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "p_ei_eap_list = []\n",
        "\n",
        "for word in s_list:\n",
        "  count = 0\n",
        "  if word in sorted_word_table.index:\n",
        "    count = sorted_word_table.loc[word, 'EAP']\n",
        "  result =  (count+1)/(eap_count + v_size)  #using smoothing\n",
        "  p_ei_eap_list.append(result)\n",
        "\n",
        "p_ei_eap_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0002220412996817408,\n",
              " 0.00018503441640145066,\n",
              " 0.0016653097476130561,\n",
              " 0.0001110206498408704,\n",
              " 0.0005921101324846421,\n",
              " 3.7006883280290134e-05,\n",
              " 7.401376656058027e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0011472133816889942,\n",
              " 7.401376656058027e-05,\n",
              " 0.0006291170157649323,\n",
              " 0.00014802753312116054,\n",
              " 0.004255791577233365,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0005180963659240619,\n",
              " 0.0001110206498408704,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00014802753312116054,\n",
              " 0.00048108948264377177,\n",
              " 0.006624232107171934,\n",
              " 0.0009991858485678337,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0017763303974539263,\n",
              " 0.0009251720820072533,\n",
              " 0.00018503441640145066,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00037006883280290133,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0006291170157649323,\n",
              " 0.0007031307823255126,\n",
              " 0.0003330619495226112,\n",
              " 7.401376656058027e-05,\n",
              " 0.0019983716971356674,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0026644955961808896,\n",
              " 0.0015912959810524758,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0003330619495226112,\n",
              " 0.00037006883280290133,\n",
              " 0.0012212271482495744,\n",
              " 0.0008141514321663829,\n",
              " 0.00014802753312116054,\n",
              " 7.401376656058027e-05,\n",
              " 0.0014802753312116053,\n",
              " 0.0006661238990452224,\n",
              " 0.00014802753312116054,\n",
              " 0.0002960550662423211,\n",
              " 0.00018503441640145066,\n",
              " 0.0002960550662423211,\n",
              " 0.00040707571608319146,\n",
              " 0.0004440825993634816,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 7.401376656058027e-05,\n",
              " 0.0019983716971356674,\n",
              " 0.0032936126119458217,\n",
              " 0.0002220412996817408,\n",
              " 0.0017763303974539263,\n",
              " 0.00014802753312116054,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 7.401376656058027e-05,\n",
              " 0.0017763303974539263,\n",
              " 0.00048108948264377177,\n",
              " 0.006624232107171934,\n",
              " 0.0008141514321663829,\n",
              " 0.00040707571608319146,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0032936126119458217,\n",
              " 0.0016653097476130561,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0003330619495226112,\n",
              " 0.0026274887129005995,\n",
              " 0.0010361927318481238,\n",
              " 0.00014802753312116054,\n",
              " 0.0009991858485678337,\n",
              " 0.00037006883280290133,\n",
              " 0.0006661238990452224,\n",
              " 0.0007771445488860928,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00040707571608319146,\n",
              " 0.0009621789652875435,\n",
              " 0.0007771445488860928,\n",
              " 0.0009251720820072533,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 0.00048108948264377177,\n",
              " 0.0026274887129005995,\n",
              " 0.0001110206498408704,\n",
              " 0.0002220412996817408,\n",
              " 0.0001110206498408704,\n",
              " 7.401376656058027e-05,\n",
              " 7.401376656058027e-05,\n",
              " 0.0001110206498408704,\n",
              " 0.0003330619495226112,\n",
              " 0.0002960550662423211,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 0.000555103249204352,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0005921101324846421,\n",
              " 7.401376656058027e-05,\n",
              " 0.0002220412996817408,\n",
              " 0.0015172822144918954,\n",
              " 0.0028865368958626305,\n",
              " 0.0004440825993634816,\n",
              " 0.0001110206498408704,\n",
              " 0.0006291170157649323,\n",
              " 0.0001110206498408704,\n",
              " 0.0001110206498408704,\n",
              " 0.0006291170157649323,\n",
              " 0.0002960550662423211,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0019983716971356674,\n",
              " 0.0002960550662423211,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0011472133816889942,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00025904818296203095,\n",
              " 0.0019983716971356674,\n",
              " 0.000555103249204352,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0009991858485678337,\n",
              " 0.0016283028643327658,\n",
              " 0.0001110206498408704,\n",
              " 0.00025904818296203095,\n",
              " 0.0016653097476130561,\n",
              " 0.00025904818296203095,\n",
              " 0.0008511583154466731,\n",
              " 0.0017763303974539263,\n",
              " 0.0009991858485678337,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0032936126119458217,\n",
              " 0.0001110206498408704,\n",
              " 0.00018503441640145066,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00014802753312116054,\n",
              " 0.0009251720820072533,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0026644955961808896,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 0.00018503441640145066,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0015172822144918954,\n",
              " 0.00040707571608319146,\n",
              " 0.0002960550662423211,\n",
              " 0.00014802753312116054,\n",
              " 0.0002220412996817408,\n",
              " 0.0026274887129005995,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0008511583154466731,\n",
              " 0.0008881651987269632,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0001110206498408704,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00048108948264377177,\n",
              " 0.0012952409148101547,\n",
              " 0.0001110206498408704,\n",
              " 0.0001110206498408704,\n",
              " 0.0003330619495226112,\n",
              " 0.0001110206498408704,\n",
              " 0.00014802753312116054,\n",
              " 0.0002220412996817408,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0007031307823255126,\n",
              " 0.0002220412996817408,\n",
              " 0.00014802753312116054,\n",
              " 0.0003330619495226112,\n",
              " 7.401376656058027e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 7.401376656058027e-05,\n",
              " 0.0007401376656058027,\n",
              " 0.00025904818296203095,\n",
              " 0.00025904818296203095,\n",
              " 7.401376656058027e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00014802753312116054,\n",
              " 0.0006291170157649323,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00037006883280290133,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0026644955961808896,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0011842202649692843,\n",
              " 0.0002220412996817408,\n",
              " 0.0001110206498408704,\n",
              " 3.7006883280290134e-05,\n",
              " 0.00018503441640145066,\n",
              " 0.0016653097476130561,\n",
              " 7.401376656058027e-05,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0015172822144918954,\n",
              " 7.401376656058027e-05,\n",
              " 0.0001110206498408704,\n",
              " 3.7006883280290134e-05,\n",
              " 0.0002220412996817408]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r03zYuZgx-AB"
      },
      "source": [
        "I am going to break out what float_product does so we can examine it more closely. If I see the product go to 0, I'll print at what value it happened. Just as reminder, it should never be 0 given all the values in p_ei_eap_list are above 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "241zXNPpwXvB",
        "outputId": "5ef092ab-b22d-407a-b9f1-51ccef070ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "product = 1.\n",
        "\n",
        "for i in range(len(p_ei_eap_list)):\n",
        "  p = p_ei_eap_list[i]\n",
        "  product = product * p\n",
        "  if product == 0:\n",
        "    print(i)\n",
        "    break  #new Python operator. It says pretend the loop has finished."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlliZFVByVnw"
      },
      "source": [
        "So we got to 0 on the 92nd item in the list. It will now stay 0 for the other 112 items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDBOkjGL0Za1"
      },
      "source": [
        "##This is an example of the vanishing gradient\n",
        "\n",
        "Technically, the jargony term *vanishing gradient* shows up later in neural net models. But I think it applies here in spirit. I like the term because of the \"vanishing\" piece: as things get smaller and smaller, the result eventually vanishes (becomes zero). That is what is happening here. The product is getting smaller and smaller and eventually vanishes at index 92."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlW0i9KoylVf"
      },
      "source": [
        "#12. Smallest Python float\n",
        "\n",
        "This begs the question how low can you go (limbo music plays in background)? What is the smallest float Python can represent?\n",
        "\n",
        "Check it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8wlQyFgzBzI",
        "outputId": "4fdc24c2-b2ed-4336-967b-6fff4887cb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "sys.float_info.min  #smallest float value possible"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2250738585072014e-308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6046BIKkzujF"
      },
      "source": [
        "Here is what I propose. If a product drops to zero (through underflow), we set the product to the minimum Python float value seen above. This avoids returning a zero probablity from Naive Bayes. We have earlier used smoothing to handle some zero values. Now we are handling the second form of zero we might see. We are good to go!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO513ylN1iQR"
      },
      "source": [
        "#Summary\n",
        "\n",
        "We started with Naive Bayes out of the box in Chapter 5. This week we have refined it by (a) adding a Laplace smoothing factor, (b) eliminating the denominator, and (c) avoiding underflow when taking the products of very small numbers in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmg5eahoLnc"
      },
      "source": [
        "#13. Ready to evaluate\n",
        "\n",
        "I packaged everything up for you into a puddles function. It handles smoothing and underflow. Given a test sentence and word bag built from the training set, it will give you the 3 values from calculating Naive Bayes. Check it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfyzpALu3y_e"
      },
      "source": [
        "e_list = ['laugh', 'oliver', 'grandfather', 'wo', 'ride', 'motor']  #from chapter 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rte853IIuYZH",
        "outputId": "cf8c0310-bc6c-4e17-b030-bf976ed0d76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "up.bayes_gothic(e_list, sorted_word_table, training_table)  #(4.797878011973764e-25, 6.306182771405084e-26, 5.553115651723025e-23)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.797878011973764e-25, 6.306182771405082e-26, 5.553115651723025e-23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIvi6bhjLBb_"
      },
      "source": [
        "HPL was the actual author of the sentence so we got it right. He has the largest value. Nice. Our first win using Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Ohyg-4Gq5d"
      },
      "source": [
        "#Assignment 1.\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Get your predictions by running Naive Bayes on the testing set. Note that this is a 2 step process: (1) get the triples for each sentence, (2) get the predictions by taking the max of each triple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggDfRg9378A"
      },
      "source": [
        "##Step 1.\n",
        "\n",
        "Produce the list of triples. So no predictions yet. Just a list of the results from `up.bayes_gothic`.\n",
        "\n",
        "This took me 3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKb6UKClTZKq"
      },
      "source": [
        "#use new list from old list gist\n",
        "\n",
        "#old list testing_text\n",
        "\n",
        "result_list = []  #new list\n",
        "\n",
        "for i in range(len(testing_text)):\n",
        "  item = testing_text[i].lower()\n",
        "\n",
        "  #loop to get e_list\n",
        "  e_list = []\n",
        "  doc = nlp(item.lower())\n",
        "\n",
        "  for i in range(len(doc)):\n",
        "    token = doc[i]\n",
        "    if token.is_alpha and not token.is_stop:\n",
        "      e_list.append(token.text)\n",
        "\n",
        "  triple = up.bayes_gothic(e_list, sorted_word_list, training_table)\n",
        "\n",
        "  result_list.append(triple)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_-sQqB34Tkg"
      },
      "source": [
        "result_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTQN9yRj5F8c"
      },
      "source": [
        "Here is what I got for result_list first 5.\n",
        "\n",
        "<pre>\n",
        "[(2.3119092333109343e-46, 5.026792223582086e-54, 2.4787413489091447e-51),\n",
        " (6.959717796952573e-45, 1.5140406188464093e-42, 3.3069010682386025e-42),\n",
        " (5.395832479210548e-48, 9.28028679134852e-51, 4.297064611846296e-50),\n",
        " (3.996284558172596e-56, 9.060867036238493e-53, 2.1497919775490074e-57),\n",
        " (1.219086935483253e-66, 1.0246639306144965e-70, 5.009110759153542e-68)]\n",
        " </pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhIHH1ZL4Uh9"
      },
      "source": [
        "##Step 2.\n",
        "\n",
        "Now get predictions. Find the max author in each triple and make that author your prediction.\n",
        "\n",
        "Here is some code that might help."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V5pVTHe27FA"
      },
      "source": [
        "authors = ['EAP', 'MWS', 'HPL']\n",
        "\n",
        "a_triple = [.5, .4, .3]  #simulates the 3 values you get from up.bayes_gothic\n",
        "\n",
        "m = max(a_triple)  #what is the max value?  .5 in our case\n",
        "j = a_triple.index(m)  #where is it found?  index 0 in our case\n",
        "a = authors[j]  #corresponding author       \"EAP\" in our case\n",
        "prediction = a  #record the prediction\n",
        "\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "bc3fda02-0e29-40d2-f2a3-ae667f8ed163",
        "id": "ZYKf80NU_sA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EAP', 'HPL', 'EAP', 'MWS', 'EAP', 'EAP', 'EAP', 'EAP', 'EAP', 'MWS']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY20ZE0DV0Kc"
      },
      "source": [
        "testing_authors[:10]  #['EAP', 'MWS', 'EAP', 'MWS', 'EAP', 'EAP', 'EAP', 'EAP', 'EAP', 'MWS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4zqeiga4n8z"
      },
      "source": [
        "#Assignment 2.\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Go ahead and compute accuracy. I got a value of `0.8180115764385427`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rErf54So_DMS"
      },
      "source": [
        "#new list from old list gist\n",
        "\n",
        "#old list is result_list\n",
        "\n",
        "predictions = []  #new list\n",
        "\n",
        "for i in range(len(result_list)):\n",
        "  triple = result_list[i]\n",
        "\n",
        "  #tricky part - find max and get author\n",
        "\n",
        "  predictions.append(pred)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP0-MWAeWQxM",
        "outputId": "6eb65aa9-ccb1-4ecc-a909-fe72232bf644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2008\n",
            "1467\n",
            "1330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FVARYtbG2zr"
      },
      "source": [
        "accuracy  #0.8180115764385427"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTL26J8VSukJ"
      },
      "source": [
        "#13. A plot in place of confusion matrix\n",
        "\n",
        "We can use a heat-map to give us a view into the 9 cases we now have. Yellow is large values, green medium and purple low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaCg66ilAJaE"
      },
      "source": [
        "zipped = list(zip(predictions, testing_authors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFrjFDwVSVZ4",
        "outputId": "0ac97d34-0003-48de-97db-f6abfbddce7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "up.heat_map(zipped, ['EAP', 'MWS', 'HPL'])  #EAP=0, MWS=1, HPL=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-8c31815e439c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'EAP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MWS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HPL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#EAP=0, MWS=1, HPL=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'zipped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wbR1_FHMUlR"
      },
      "source": [
        "##What would a cost model look like?\n",
        "\n",
        "A bit of a stretch, but let's say that it is costly to falsely predict EAP. You can see we have 2 false-negative cases in column 0: predicting EAP when it was MWS; predicting EAP when it was HPL. These mistakes are costly because the price for legit EAP sentences is high. Investors are willing to fork out big bucks for legit EAP sentences (bigggg stretch). If we predict a sentence is EAP, someone buys it for a high price, and they later discover it is not authored by EAP, we get sued. So we might consider ways of lowering (0,1) and (0,2) cells, 282 and 140 respectively.\n",
        "\n",
        "Sorry, that is my best shot at a back-story."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wztldif4qVdt"
      },
      "source": [
        "#14. Multinomial versus Bernoulli\n",
        "\n",
        "We are using Multinomial Naive Bayes because we are counting how many times a word occurs for an author. We could also use Bernoulli Naive Bayes where we look for features that are true or false, e.g., EAP uses the word 'oliver', true or false - don't care how many times beyond 1. This paper discusses the difference between the two: http://www.kamalnigam.com/papers/multinomial-aaaiws98.pdf.  Short answer: Multinomial wins with a large word bag, which we have.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04LxayGq6-2L"
      },
      "source": [
        "#15. End notes\n",
        "\n",
        "This ends our look at Naive Bayes applied to a text classification/prediction problem. What do you think? Is our accuracy result of 82% good enough? The question is whether other models, e.g., KNN, can do better?  Straight out of the gate with KNN, we would require 21K columns, one for each word in `sorted_word_bag`. We could try to reduce that 21K down to a smaller number. We will take up a related problem in the next chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz19-N2ygRO-"
      },
      "source": [
        "#On Wednesday\n",
        "\n",
        "I'll hand out take-home midterm and go over it. It will be due before class on Monday of week 7. It will count on you being able to pull together ideas from both chapters 5 and 6."
      ]
    }
  ]
}